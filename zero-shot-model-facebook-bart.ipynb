{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_metric\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Project Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the nation that gave the world the Magna Carta...</td>\n",
       "      <td>Loaded_Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a striking blow against freedom</td>\n",
       "      <td>Loaded_Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a complete travesty of justice</td>\n",
       "      <td>Loaded_Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firestorm of outrage</td>\n",
       "      <td>Loaded_Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aggressively stuck his tongue in my mouth\"</td>\n",
       "      <td>Loaded_Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>our president</td>\n",
       "      <td>Jingoism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>our nation's history</td>\n",
       "      <td>Jingoism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Americans</td>\n",
       "      <td>Jingoism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>protect America</td>\n",
       "      <td>Jingoism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>our</td>\n",
       "      <td>Jingoism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence        Technique\n",
       "0    the nation that gave the world the Magna Carta...  Loaded_Language\n",
       "1                      a striking blow against freedom  Loaded_Language\n",
       "2                       a complete travesty of justice  Loaded_Language\n",
       "3                                 firestorm of outrage  Loaded_Language\n",
       "4           aggressively stuck his tongue in my mouth\"  Loaded_Language\n",
       "..                                                 ...              ...\n",
       "498                                      our president         Jingoism\n",
       "499                               our nation's history         Jingoism\n",
       "500                                          Americans         Jingoism\n",
       "501                                    protect America         Jingoism\n",
       "502                                                our         Jingoism\n",
       "\n",
       "[503 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Neutral Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_data = pd.read_csv('neutral_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Water boils at 100 degrees Celsius.</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Earth revolves around the Sun.</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The summit of Mount Everest is about 8,848 met...</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Pacific Ocean is the largest ocean on Earth.</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Photosynthesis is the process by which green p...</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Some species of starfish can regenerate lost l...</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>The world's first artificial heart transplant ...</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>The population of the Earth's data is constant...</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Some species of spiders can spin webs that are...</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>The world's first successful virtual reality e...</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence Technique\n",
       "0                  Water boils at 100 degrees Celsius.   Nothing\n",
       "1                   The Earth revolves around the Sun.   Nothing\n",
       "2    The summit of Mount Everest is about 8,848 met...   Nothing\n",
       "3     The Pacific Ocean is the largest ocean on Earth.   Nothing\n",
       "4    Photosynthesis is the process by which green p...   Nothing\n",
       "..                                                 ...       ...\n",
       "395  Some species of starfish can regenerate lost l...   Nothing\n",
       "396  The world's first artificial heart transplant ...   Nothing\n",
       "397  The population of the Earth's data is constant...   Nothing\n",
       "398  Some species of spiders can spin webs that are...   Nothing\n",
       "399  The world's first successful virtual reality e...   Nothing\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Technique\n",
       "Hyperbole          101\n",
       "Doubt              101\n",
       "no_propaganda      101\n",
       "Loaded_Language    100\n",
       "Jingoism           100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Technique'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_df(old_df: pd.DataFrame, cycles: int = 1) -> pd.DataFrame:\n",
    "  for i in range(cycles):\n",
    "    new_df = old_df.sample(frac=1).reset_index(drop=True)\n",
    "  return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_data['Technique'] = neutral_data['Technique'].replace('Nothing', 'no_propaganda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Water boils at 100 degrees Celsius.</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Earth revolves around the Sun.</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The summit of Mount Everest is about 8,848 met...</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Pacific Ocean is the largest ocean on Earth.</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Photosynthesis is the process by which green p...</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Some species of starfish can regenerate lost l...</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>The world's first artificial heart transplant ...</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>The population of the Earth's data is constant...</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Some species of spiders can spin webs that are...</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>The world's first successful virtual reality e...</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence      Technique\n",
       "0                  Water boils at 100 degrees Celsius.  no_propaganda\n",
       "1                   The Earth revolves around the Sun.  no_propaganda\n",
       "2    The summit of Mount Everest is about 8,848 met...  no_propaganda\n",
       "3     The Pacific Ocean is the largest ocean on Earth.  no_propaganda\n",
       "4    Photosynthesis is the process by which green p...  no_propaganda\n",
       "..                                                 ...            ...\n",
       "395  Some species of starfish can regenerate lost l...  no_propaganda\n",
       "396  The world's first artificial heart transplant ...  no_propaganda\n",
       "397  The population of the Earth's data is constant...  no_propaganda\n",
       "398  Some species of spiders can spin webs that are...  no_propaganda\n",
       "399  The world's first successful virtual reality e...  no_propaganda\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating manually labeled data with Facts/Neutral statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, neutral_data[:100]], ignore_index = True)\n",
    "\n",
    "data = shuffle_df(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>local and federal authorities are refusing to ...</td>\n",
       "      <td>Doubt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an extraordinary public service</td>\n",
       "      <td>Hyperbole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lied to the country</td>\n",
       "      <td>Jingoism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inexhaustible mercy and forgiveness</td>\n",
       "      <td>Hyperbole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a complete travesty of justice</td>\n",
       "      <td>Loaded_Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>American people</td>\n",
       "      <td>Jingoism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>That the neo Catholic establishment refuses to...</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>our</td>\n",
       "      <td>Jingoism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>for normalizing a regime routinely called out ...</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>unlimited warfare against non-Muslims</td>\n",
       "      <td>Hyperbole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence        Technique\n",
       "0    local and federal authorities are refusing to ...            Doubt\n",
       "1                      an extraordinary public service        Hyperbole\n",
       "2                                  lied to the country         Jingoism\n",
       "3                  inexhaustible mercy and forgiveness        Hyperbole\n",
       "4                       a complete travesty of justice  Loaded_Language\n",
       "..                                                 ...              ...\n",
       "498                                    American people         Jingoism\n",
       "499  That the neo Catholic establishment refuses to...    no_propaganda\n",
       "500                                                our         Jingoism\n",
       "501  for normalizing a regime routinely called out ...    no_propaganda\n",
       "502              unlimited warfare against non-Muslims        Hyperbole\n",
       "\n",
       "[503 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and test set\n",
    "\n",
    "train_data = data[:int(len(data)*0.8)]\n",
    "test_data = data[int(len(data)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>local and federal authorities are refusing to ...</td>\n",
       "      <td>Doubt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an extraordinary public service</td>\n",
       "      <td>Hyperbole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lied to the country</td>\n",
       "      <td>Jingoism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inexhaustible mercy and forgiveness</td>\n",
       "      <td>Hyperbole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a complete travesty of justice</td>\n",
       "      <td>Loaded_Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Whether the Trump administration follows throu...</td>\n",
       "      <td>Doubt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>I thought my life was over</td>\n",
       "      <td>Hyperbole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>a chronic confusion seems to mark your pontifi...</td>\n",
       "      <td>Loaded_Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>American blood</td>\n",
       "      <td>Jingoism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>we defend the Roman Pontiff</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence        Technique\n",
       "0    local and federal authorities are refusing to ...            Doubt\n",
       "1                      an extraordinary public service        Hyperbole\n",
       "2                                  lied to the country         Jingoism\n",
       "3                  inexhaustible mercy and forgiveness        Hyperbole\n",
       "4                       a complete travesty of justice  Loaded_Language\n",
       "..                                                 ...              ...\n",
       "397  Whether the Trump administration follows throu...            Doubt\n",
       "398                         I thought my life was over        Hyperbole\n",
       "399  a chronic confusion seems to mark your pontifi...  Loaded_Language\n",
       "400                                     American blood         Jingoism\n",
       "401                        we defend the Roman Pontiff    no_propaganda\n",
       "\n",
       "[402 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>a natural disaster of a magnitude not seen in ...</td>\n",
       "      <td>Hyperbole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>watershed moment in U.S. and world history, an...</td>\n",
       "      <td>Hyperbole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>And if so, could we have been this wrong</td>\n",
       "      <td>Doubt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>At some point, the American people will be for...</td>\n",
       "      <td>Jingoism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>the most unprecedented persecution</td>\n",
       "      <td>Hyperbole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>American people</td>\n",
       "      <td>Jingoism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>That the neo Catholic establishment refuses to...</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>our</td>\n",
       "      <td>Jingoism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>for normalizing a regime routinely called out ...</td>\n",
       "      <td>no_propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>unlimited warfare against non-Muslims</td>\n",
       "      <td>Hyperbole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence      Technique\n",
       "402  a natural disaster of a magnitude not seen in ...      Hyperbole\n",
       "403  watershed moment in U.S. and world history, an...      Hyperbole\n",
       "404           And if so, could we have been this wrong          Doubt\n",
       "405  At some point, the American people will be for...       Jingoism\n",
       "406                 the most unprecedented persecution      Hyperbole\n",
       "..                                                 ...            ...\n",
       "498                                    American people       Jingoism\n",
       "499  That the neo Catholic establishment refuses to...  no_propaganda\n",
       "500                                                our       Jingoism\n",
       "501  for normalizing a regime routinely called out ...  no_propaganda\n",
       "502              unlimited warfare against non-Muslims      Hyperbole\n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_data, split=\"train\")\n",
    "test_ds = Dataset.from_pandas(test_data, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_to_int = ['Name_Calling,Labeling', 'Nothing', 'Loaded_Language','Repetition','Doubt','Exaggeration,Minimisation','Flag-Waving','Causal_Oversimplification']\n",
    "\n",
    "#Flag-Waving - Jingoism\n",
    "#Exaageration and Minimization - Hyperbole\n",
    "#Causal-Simplification - Simplification\n",
    "#Name_Calling, Labelling - NameCalling\n",
    "label_to_int = ['Loaded_Language','Doubt','Hyperbole','Jingoism', 'no_propaganda']\n",
    "template = \"This example is {}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizerFast\n",
    "\n",
    "tokenizer = BartTokenizerFast.from_pretrained('facebook/bart-large-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_sequence(sample):\n",
    "  text = sample[\"Sentence\"]\n",
    "  label = sample[\"Technique\"][0]\n",
    "  contradiction_label = random.choice([x for x in label_to_int if x != label])\n",
    "  encoded_sequence = tokenizer(text * 2, [template.format(label), template.format(contradiction_label)], truncation = True, padding = 'max_length')\n",
    "  encoded_sequence[\"labels\"] = [2, 0]\n",
    "  encoded_sequence[\"input_sentence\"] = tokenizer.batch_decode(encoded_sequence.input_ids)\n",
    "  return encoded_sequence\n",
    "\n",
    "\n",
    "train_dataset = train_ds.map(create_input_sequence, batched = True, batch_size = 1, remove_columns = [\"Sentence\", \"Technique\"])\n",
    "test_dataset = test_ds.map(create_input_sequence, batched = True, batch_size = 1, remove_columns = [\"Sentence\", \"Technique\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForSequenceClassification, Trainer, TrainingArguments, EvalPrediction\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "  metric_acc = load_metric(\"accuracy\")\n",
    "  metric_f1 = load_metric(\"f1\")\n",
    "  preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "  preds = np.argmax(preds, axis = 1)\n",
    "  result = {}\n",
    "  result[\"accuracy\"] = metric_acc.compute(predictions = preds, references = p.label_ids)[\"accuracy\"]\n",
    "  result[\"f1\"] = metric_f1.compute(predictions = preds, references = p.label_ids, average = 'macro')[\"f1\"]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"Result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large-mnli and are newly initialized because the shapes did not match:\n",
      "- classification_head.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classification_head.out_proj.weight: found shape torch.Size([3, 1024]) in the checkpoint and torch.Size([5, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/thakker.shi/.local/lib/python3.8/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir = model_directory,      # Output directory\n",
    "  num_train_epochs = 5,             # Total number of training epochs\n",
    "  per_device_train_batch_size = 16,  # Batch size per device during training\n",
    "  per_device_eval_batch_size = 64,   # Batch size for evaluation\n",
    "  warmup_steps = 500,                # Number of warmup steps for learning rate scheduler\n",
    "  weight_decay = 0.01,               # Strength of weight decay\n",
    "  logging_strategy='steps',\n",
    "  logging_steps=100,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  eval_steps=100,\n",
    "  save_strategy=\"steps\", \n",
    ")\n",
    "\n",
    "\n",
    "model = BartForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\", num_labels = len(label_to_int), ignore_mismatched_sizes = True)\n",
    "\n",
    "trainer = Trainer(\n",
    "  model = model,                     # The instantiated model to be trained\n",
    "  args = training_args,              # Training arguments, defined above\n",
    "  compute_metrics = compute_metrics, # A function to compute the metrics\n",
    "  train_dataset = train_dataset,     # Training dataset\n",
    "  eval_dataset = test_dataset,       # Evaluation dataset\n",
    "  tokenizer = tokenizer              # The tokenizer that was used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='255' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 18/255 1:15:51 < 18:43:38, 0.00 it/s, Epoch 0.33/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 02:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thakker.shi/.local/lib/python3.8/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/thakker.shi/.local/lib/python3.8/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5946733951568604,\n",
       " 'eval_accuracy': 0.8512396694214877,\n",
       " 'eval_f1': 0.8509852216748768,\n",
       " 'eval_runtime': 208.0203,\n",
       " 'eval_samples_per_second': 1.163,\n",
       " 'eval_steps_per_second': 0.019,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "classifier = pipeline(\"zero-shot-classification\", model = model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jingoism\n",
      "Jingoism\n",
      "Jingoism\n",
      "Loaded_Language\n",
      "Hyperbole\n",
      "Loaded_Language\n",
      "Jingoism\n",
      "Loaded_Language\n",
      "Jingoism\n",
      "Loaded_Language\n",
      "10 Completed\n",
      "Doubt\n",
      "Loaded_Language\n",
      "Doubt\n",
      "Loaded_Language\n",
      "Doubt\n",
      "Doubt\n",
      "Doubt\n",
      "Doubt\n",
      "Doubt\n",
      "Doubt\n",
      "10 Completed\n",
      "Doubt\n",
      "Loaded_Language\n",
      "Doubt\n",
      "Doubt\n",
      "Doubt\n",
      "Doubt\n",
      "Doubt\n",
      "Loaded_Language\n",
      "Doubt\n",
      "Loaded_Language\n",
      "10 Completed\n",
      "Doubt\n",
      "Loaded_Language\n",
      "Doubt\n",
      "Loaded_Language\n",
      "Doubt\n",
      "Doubt\n",
      "Doubt\n",
      "Loaded_Language\n",
      "Doubt\n",
      "Doubt\n",
      "10 Completed\n",
      "Doubt\n",
      "Doubt\n",
      "Doubt\n",
      "Doubt\n",
      "Doubt\n",
      "Doubt\n"
     ]
    }
   ],
   "source": [
    "# sequences = \"it seems that perhaps even his legendary\"\n",
    "Sentence = [\"Is our competitor really committed to the environment, or is it just a marketing tactic?\"]\n",
    "\n",
    "count=0\n",
    "for sequences in Sentence:\n",
    "    label_to_int=['Loaded_Language','Doubt','Hyperbole','Jingoism', 'no_propaganda']\n",
    "\n",
    "    print(classifier(sequences, label_to_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('model/tokenizer_config.json',\n",
       " 'model/special_tokens_map.json',\n",
       " 'model/vocab.json',\n",
       " 'model/merges.txt',\n",
       " 'model/added_tokens.json',\n",
       " 'model/tokenizer.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path=\"model\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1', '2': 'LABEL_2', '3': 'LABEL_3', '4': 'LABEL_4'}. The number of labels wil be overwritten to 5.\n"
     ]
    }
   ],
   "source": [
    "model = BartForSequenceClassification.from_pretrained('model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
